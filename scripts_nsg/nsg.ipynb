{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import random\n",
    "import time\n",
    "import bisect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Neighbor:\n",
    "    def __init__(self, id, distance, flag):\n",
    "        self.id = id\n",
    "        self.distance = distance\n",
    "        self.flag = flag\n",
    "\n",
    "    def __lt__(self, other: 'Neighbor'):\n",
    "        return self.distance < other.distance\n",
    "    \n",
    "    def printNeighbor(self):\n",
    "        print(\"id: \", self.id, \"distance: \", self.distance, \"flag: \", self.flag)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### NSG Index structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare(query_data, db_vec, dimension: int):\n",
    "    return np.sum((query_data - db_vec) ** 2)\n",
    "\n",
    "def print_retset(retset):\n",
    "    for i in range(len(retset)):\n",
    "        retset[i].printNeighbor()\n",
    "        \n",
    "class IndexNSG():\n",
    "    def __init__(self, dimension: int, n: int):\n",
    "        self.final_graph = []\n",
    "        self.dimension = dimension\n",
    "        self.width = 0\n",
    "        self.ep_ = 0\n",
    "        self.nd_ = n\n",
    "    \n",
    "    def Load(self, filename: str):\n",
    "        with open(filename, \"rb\") as f:\n",
    "            self.width = int.from_bytes(f.read(4), byteorder='little', signed=False)\n",
    "            self.ep_ = int.from_bytes(f.read(4), byteorder='little', signed=False)\n",
    "            cc = 0\n",
    "            while True:\n",
    "                k_bytes = f.read(4)\n",
    "                if not k_bytes:\n",
    "                    break\n",
    "                k = int.from_bytes(k_bytes, byteorder='little', signed=False)\n",
    "                cc += k\n",
    "                tmp = list(np.frombuffer(f.read(k * 4), dtype=np.uint32))\n",
    "                self.final_graph.append(tmp)\n",
    "            cc //= self.nd_\n",
    "            # print(cc)\n",
    "\n",
    "    def search_with_base_graph(self, query, x, K, parameters):\n",
    "        L = parameters['L_search']\n",
    "        data_ = x\n",
    "        retset:list[Neighbor] = []\n",
    "        init_ids = []\n",
    "        flags = [0] * self.nd_\n",
    "        node_counter = 0\n",
    "        \n",
    "        for tmp_l in range(min(L, len(self.final_graph[self.ep_]))):\n",
    "            init_ids.append(self.final_graph[self.ep_][tmp_l])\n",
    "            flags[init_ids[tmp_l]] = 1\n",
    "        \n",
    "        tmp_l += 1\n",
    "    \n",
    "        while tmp_l < L:\n",
    "            id = random.randint(0, self.nd_ - 1)\n",
    "            if flags[id] == 1:\n",
    "                continue\n",
    "            flags[id] = 1\n",
    "            init_ids.append(id)\n",
    "            tmp_l += 1\n",
    "\n",
    "        for i in range(len(init_ids)):\n",
    "            id = init_ids[i]\n",
    "            dist = compare(data_[id], query, self.dimension)\n",
    "            retset.append(Neighbor(id, dist, 1))\n",
    "        \n",
    "        node_counter += len(init_ids)\n",
    "        \n",
    "        retset.sort()\n",
    "\n",
    "        # for item in retset[:L]:\n",
    "        #     print(item.id, \" \", end=\"\")\n",
    "        # print(\"\")\n",
    "        \n",
    "        # cc = 0\n",
    "        k = 0\n",
    "        while k < L:\n",
    "            # cc += 1\n",
    "            nk = L\n",
    "            if retset[k].flag:\n",
    "                retset[k].flag = 0\n",
    "                n = retset[k].id\n",
    "                \n",
    "                # if cc < 10:\n",
    "                #     print(n, \" \", end=\"\")\n",
    "        \n",
    "                for m in range(len(self.final_graph[n])):\n",
    "                    id = self.final_graph[n][m]\n",
    "                    if flags[id] == 1:\n",
    "                        continue\n",
    "                    flags[id] = 1\n",
    "                    dist = compare(query, data_[id], self.dimension)\n",
    "                    node_counter += 1\n",
    "                    if dist >= retset[L - 1].distance:\n",
    "                        continue\n",
    "                    nn = Neighbor(id, dist, 1)\n",
    "                    bisect.insort_left(retset, nn)\n",
    "                    r = retset.index(nn)\n",
    "                    if r < nk:\n",
    "                        nk = r\n",
    "                    # nk: the index of the smallest dist\n",
    "            \n",
    "            # if cc > 0:\n",
    "            #     print(\"cc:\", cc, end=\"\\t\")\n",
    "            #     for item in retset[:L]:\n",
    "            #         print(item.id, \"\\t\", end=\"\")\n",
    "            #     print(\"\")\n",
    "            #     print(\"\\t\", end=\"\")\n",
    "            #     for item in retset[:L]:\n",
    "            #         print(item.flag, \"\\t\", end=\"\")\n",
    "            #     print(\"\")\n",
    "            \n",
    "            if nk <= k:\n",
    "                k = nk\n",
    "            else:  \n",
    "                k += 1\n",
    "                \n",
    "        # print_retset(retset)\n",
    "        \n",
    "        indices = [0] * K\n",
    "        for i in range(K):\n",
    "            indices[i] = retset[i].id\n",
    "        \n",
    "        # print(cc)\n",
    "        return (indices, node_counter)\n",
    "\n",
    "    def search_with_base_graph_2queue(self, query, x, K, parameters):\n",
    "        L = parameters['L_search']\n",
    "        data_ = x\n",
    "        candidate_set:list[Neighbor] = []\n",
    "        top_candidates:list[Neighbor] = []\n",
    "        node_counter = 0\n",
    "        \n",
    "        init_ids = []\n",
    "        flags = [0] * self.nd_\n",
    "        \n",
    "        for tmp_l in range(min(L, len(self.final_graph[self.ep_]))):\n",
    "            init_ids.append(self.final_graph[self.ep_][tmp_l])\n",
    "            flags[init_ids[tmp_l]] = 1\n",
    "    \n",
    "        while tmp_l < L:\n",
    "            id = random.randint(0, self.nd_ - 1)\n",
    "            if flags[id] == 1:\n",
    "                continue\n",
    "            flags[id] = 1\n",
    "            init_ids.append(id)\n",
    "            tmp_l += 1\n",
    "\n",
    "        for i in range(len(init_ids)):\n",
    "            id = init_ids[i]\n",
    "            dist = compare(data_[id], query, self.dimension)\n",
    "            candidate_set.append(Neighbor(id, dist, 1))\n",
    "            top_candidates.append(Neighbor(id, dist, 1))\n",
    "        \n",
    "        node_counter += len(init_ids)\n",
    "        \n",
    "        candidate_set.sort()\n",
    "        top_candidates.sort()\n",
    "        \n",
    "        # cc = 0\n",
    "        while len(candidate_set) > 0:\n",
    "            # cc += 1\n",
    "            cur_node = candidate_set.pop(0)\n",
    "            \n",
    "            if cur_node.distance > top_candidates[L - 1].distance:  # here we assume both queues has infinite capacity\n",
    "                break\n",
    "            \n",
    "            cur_id = cur_node.id\n",
    "            \n",
    "            # if cc < 10:\n",
    "            #     print(cur_id, \" \", end=\"\")\n",
    "\n",
    "            for m in range(len(self.final_graph[cur_id])):\n",
    "                id = self.final_graph[cur_id][m]\n",
    "                if flags[id] == 1:\n",
    "                    continue\n",
    "                flags[id] = 1\n",
    "                dist = compare(query, data_[id], self.dimension)\n",
    "                node_counter += 1\n",
    "                if dist >= top_candidates[L - 1].distance:  # here L-1 is a relaxed condition ???\n",
    "                    continue\n",
    "                nn = Neighbor(id, dist, 1)\n",
    "                bisect.insort_left(candidate_set, nn)\n",
    "                bisect.insort_left(top_candidates, nn)\n",
    "        \n",
    "        \n",
    "        indices = [0] * K\n",
    "        for i in range(K):\n",
    "            indices[i] = top_candidates[i].id\n",
    "        \n",
    "        \n",
    "        return (indices, node_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load .fvecs data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_load:  (1000000, 128)\n",
      "query_load:  (10000, 128)\n",
      "gt_load:  (10000, 100)\n"
     ]
    }
   ],
   "source": [
    "def load_data(filename):\n",
    "    with open(filename, \"rb\") as file:\n",
    "        dim_bytes = file.read(4)  # Read 4 bytes for dimension\n",
    "        dim = int.from_bytes(dim_bytes, byteorder='little')  # Convert bytes to integer for dimension\n",
    "\n",
    "        file.seek(0, 2)  # Move the file pointer to the end\n",
    "        fsize = file.tell()  # Get the file size\n",
    "        num = fsize // ((dim + 1) * 4)  # Calculate the number of data points\n",
    "\n",
    "        file.seek(0)  # Move the file pointer back to the beginning\n",
    "        data = np.empty((num, dim), dtype=np.float32)  # Create an empty numpy array to store data\n",
    "\n",
    "        for i in range(num):\n",
    "            file.seek(4, 1)  # Move the file pointer forward by 4 bytes to skip index\n",
    "            data[i] = np.fromfile(file, dtype=np.float32, count=dim)  # Read dim number of float values\n",
    "\n",
    "    return data, num, dim\n",
    "\n",
    "def ivecs_read(fname):\n",
    "    a = np.fromfile(fname, dtype='int32')\n",
    "    d = a[0]\n",
    "    # Wenqi: Format of ground truth (for 10000 query vectors):\n",
    "    #   1000(topK), [1000 ids]\n",
    "    #   1000(topK), [1000 ids]\n",
    "    #        ...     ...\n",
    "    #   1000(topK), [1000 ids]\n",
    "    # 10000 rows in total, 10000 * 1001 elements, 10000 * 1001 * 4 bytes\n",
    "    return a.reshape(-1, d + 1)[:, 1:].copy()\n",
    "\n",
    "# Change to the path of your data\n",
    "data_load, points_num, dim = load_data(\"/mnt/scratch/wenqi/Faiss_experiments/sift1M//sift_base.fvecs\")\n",
    "query_load, query_num, query_dim = load_data(\"/mnt/scratch/wenqi/Faiss_experiments/sift1M/sift_query.fvecs\")\n",
    "assert(dim == query_dim)\n",
    "\n",
    "gt_load = ivecs_read(\"/mnt/scratch/wenqi/Faiss_experiments/sift1M/sift_groundtruth.ivecs\")\n",
    "\n",
    "print(\"data_load: \", np.shape(data_load))\n",
    "print(\"query_load: \", np.shape(query_load))\n",
    "print(\"gt_load: \", np.shape(gt_load))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "index = IndexNSG(dim, points_num)\n",
    "index.Load(\"sift1m.nsg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process queries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "acc:  0.0055 avg_counter:  1024.55\n"
     ]
    }
   ],
   "source": [
    "K = 100\n",
    "L = 100\n",
    "assert(L >= K)\n",
    "qsize = 100\n",
    "paras = {'L_search': L}\n",
    "# for i in range(query_num):\n",
    "# for i in range(1):\n",
    "#     index.search_with_base_graph(query_load[i], data_load, K, paras)\n",
    "\n",
    "total = 0\n",
    "correct = 0\n",
    "\n",
    "total_counter = 0\n",
    "\n",
    "for i in range(qsize):\n",
    "    indices, node_counter = index.search_with_base_graph(query_load[i], data_load, K, paras)\n",
    "    total_counter += node_counter\n",
    "    gt = gt_load[i]\n",
    "    g = set(gt)\n",
    "    total += len(gt)\n",
    "    \n",
    "    for item in indices:\n",
    "        if item in g:\n",
    "            correct += 1\n",
    "\n",
    "acc = 1.0 * correct / total\n",
    "avg_counter = 1.0 * total_counter / qsize\n",
    "print(\"acc: \", acc, \"avg_counter: \", avg_counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "search:\n",
    "123065  154617  123741  154491  620808  \n",
    "cc: 1\t704709 \t946422 \t957180 \t188228 \t75672 \t\n",
    "\t1 \t1 \t1 \t1 \t1 \t\n",
    "cc: 2\t935185 \t232764 \t285450 \t809320 \t173180 \t\n",
    "\t1 \t1 \t1 \t1 \t1 \t\n",
    "cc: 3\t746931 \t538785 \t753423 \t393275 \t935185 \t\n",
    "\t1 \t1 \t1 \t1 \t0 \t\n",
    "cc: 4\t934876 \t600499 \t746931 \t886630 \t394507 \t\n",
    "\t1 \t1 \t0 \t1 \t1 \t\n",
    "cc: 5\t932085 \t934876 \t695756 \t600499 \t746931 \t\n",
    "\t1 \t0 \t1 \t1 \t0 \t\n",
    "cc: 6\t932085 \t934876 \t695756 \t600499 \t746931 \t\n",
    "\t0 \t0 \t1 \t1 \t0 \t\n",
    "cc: 7\t932085 \t934876 \t695756 \t600499 \t746931 \t\n",
    "\t0 \t0 \t1 \t1 \t0 \t\n",
    "cc: 8\t932085 \t934876 \t695756 \t600499 \t746931 \t\n",
    "\t0 \t0 \t0 \t1 \t0 \t\n",
    "cc: 9\t932085 \t934876 \t695756 \t600499 \t562167 \t\n",
    "\t0 \t0 \t0 \t0 \t1 \t\n",
    "cc: 10\t932085 \t934876 \t695756 \t562594 \t600499 \t\n",
    "\t0 \t0 \t0 \t1 \t0 \t\n",
    "cc: 11\t932085 \t934876 \t695756 \t562594 \t600499 \t\n",
    "\t0 \t0 \t0 \t0 \t0 \t\n",
    "cc: 12\t932085 \t934876 \t695756 \t562594 \t600499 \t\n",
    "\t0 \t0 \t0 \t0 \t0 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare():\n",
    "    # TODO\n",
    "    return 0.0\n",
    "\n",
    "\n",
    "\n",
    "# define but not used\n",
    "def search_with_opt_graph(query, K, parameters, indices):\n",
    "    L = parameters['L_search']\n",
    "    \n",
    "    retset:list[Neighbor] = []\n",
    "    init_ids = []\n",
    "    flags = [0] * nd_\n",
    "    \n",
    "    neighbors = opt_graph[node_size * ep_ + data_len:]\n",
    "    MaxM_ep = neighbors[0]\n",
    "    neighbors = neighbors[1:]\n",
    "    \n",
    "    for tmp_l in range(min(L, MaxM_ep)):\n",
    "        init_ids.append(neighbors[tmp_l])\n",
    "        flags[init_ids[tmp_l]] = 1\n",
    "    \n",
    "    while tmp_l < L:\n",
    "        id = random.randint(0, nd_ - 1)\n",
    "        if flags[id] == 1:\n",
    "            continue\n",
    "        flags[id] = 1\n",
    "        init_ids.append(id)\n",
    "        tmp_l += 1\n",
    "    \n",
    "    L = 0\n",
    "    for i in range(len(init_ids)):\n",
    "        id = init_ids[i]\n",
    "        if id >= nd_:\n",
    "            continue\n",
    "        x = opt_graph[node_size * id:]\n",
    "        norm_x = x[0]\n",
    "        x = x[1:]\n",
    "        dist = compare(x, query, norm_x, dimension_)\n",
    "        retset.append(Neighbor(id, dist, 1))\n",
    "        flags[id] = 1\n",
    "        L += 1\n",
    "    \n",
    "    retset.sort()\n",
    "    k = 0\n",
    "    while k < L:\n",
    "        nk = L\n",
    "        \n",
    "        if retset[k].flag:\n",
    "            retset[k].flag = 0\n",
    "            n = retset[k].id\n",
    "            neighbors = opt_graph[node_size * n + data_len:]\n",
    "            MaxM = neighbors[0]\n",
    "            neighbors = neighbors[1:]\n",
    "            for m in range(MaxM):\n",
    "                id = neighbors[m]\n",
    "                if flags[id] == 1:\n",
    "                    continue\n",
    "                data = opt_graph[node_size * id:]\n",
    "                norm = data[0]\n",
    "                data = data[1:]\n",
    "                dist = compare(query, data, norm, dimension_)\n",
    "                if dist >= retset[L - 1].distance:\n",
    "                    continue\n",
    "                nn = Neighbor(id, dist, 1)\n",
    "                r = InsertIntoPool(retset.data(), L, nn)\n",
    "                if r < nk:\n",
    "                    nk = r\n",
    "        \n",
    "        if nk <= k:\n",
    "            k = nk\n",
    "        else:  \n",
    "            k += 1\n",
    "    \n",
    "    for i in range(K):\n",
    "        indices[i] = retset[i].id\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
